import os
import pickle
import numpy as np
import pandas as pd
import faiss
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv
from openai import OpenAI  # Upstage API ì‚¬ìš©

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Upstage API í‚¤ ì„¤ì •
api_key = os.getenv("UPSTAGE_API_KEY")
if not api_key:
    print("UPSTAGE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# Upstage API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    api_key=api_key,
    base_url="https://api.upstage.ai/v1/solar"
)

# ğŸ“Œ ì—‘ì…€ íŒŒì¼ ëª©ë¡ ë° ì‹œíŠ¸ ì§€ì •
excel_files = [
    ("data_source/ì„¸ë¬´ì‚¬ ë°ì´í„°ì „ì²˜ë¦¬_20250116.xlsx", ["Sheet1"]),
]

# âœ… ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
documents = []

# ğŸ“Œ ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„° ì½ì–´ì˜¤ê¸°
for file, sheets in excel_files:
    for sheet in sheets:
        # ì—‘ì…€ ë°ì´í„° ë¡œë“œ
        df = pd.read_excel(file, engine='openpyxl', sheet_name=sheet)

        # NaN ë°ì´í„° ì œê±°
        df = df.dropna(subset=["ì œëª©", "ë³¸ë¬¸_ì›ë³¸"])

        # ê° í–‰ì„ Documentë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        for _, row in df.iterrows():
            content = f"ì œëª©: {row['ì œëª©']}\në³¸ë¬¸: {row['ë³¸ë¬¸_ì›ë³¸']}"
            source = f"{file.replace('data_source/', '')}__{sheet}"

            metadata = {
                "íŒŒì¼ëª…": row.get("íŒŒì¼ëª…", ""),
                "ë¬¸ì„œëª…": row.get("ë¬¸ì„œëª…", ""),
                "ì œëª©": row["ì œëª©"],
                "ë³¸ë¬¸_ì›ë³¸": row["ë³¸ë¬¸_ì›ë³¸"],
                "source": source
            }

            documents.append(Document(page_content=content, metadata=metadata))

# âœ… ë°ì´í„° ê°œìˆ˜ ì¶œë ¥
print(f"âœ… ì—‘ì…€ì—ì„œ ì½ì€ ì´ ë¬¸ì„œ ê°œìˆ˜: {len(documents)}")

# ğŸ“Œ ë¬¸ì„œ ë‚´ìš© ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì„ë² ë”©í•  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ)
text_contents = [doc.page_content for doc in documents]

# ğŸ“Œ Upstage APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„±
def get_upstage_embedding(texts):
    """
    Upstage APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ìƒì„± (batch_size=100)
    """
    embeddings = []
    batch_size = 100  # Upstage API ìµœëŒ€ ìš”ì²­ ê°œìˆ˜
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        try:
            response = client.embeddings.create(
                model="embedding-passage",
                input=batch_texts
            )
            batch_embeddings = [item.embedding for item in response.data]
            embeddings.extend(batch_embeddings)
        except Exception as e:
            print(f"ğŸš¨ ì„ë² ë”© ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
    return embeddings

# âœ… ì„ë² ë”© ìƒì„± ì‹œì‘
embeddings = get_upstage_embedding(text_contents)
print(len(embeddings))
if len(embeddings) != len(documents):
    print("ğŸš¨ ì„ë² ë”© ê°œìˆ˜ê°€ ë¬¸ì„œ ê°œìˆ˜ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    exit()

# ğŸ“Œ FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„± (ìˆ˜ì •ëœ ë¶€ë¶„)
dimension = len(embeddings[0])  # Upstage ì„ë² ë”© ë²¡í„° ì°¨ì›
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings, dtype=np.float32))

# ğŸ“Œ FAISS ì¸ë±ìŠ¤ì— ë§ê²Œ index_to_docstore_id ìƒì„±
index_to_docstore_id = {i: str(i) for i in range(len(documents))}
docstore = {str(i): doc for i, doc in enumerate(documents)}

vectorstore = FAISS(
    embedding_function=None,  # Upstage APIë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í•„ìš” ì—†ìŒ
    index=index,
    docstore=docstore,
    index_to_docstore_id=index_to_docstore_id
)

# ğŸ“Œ FAISS ë²¡í„° ì €ì¥ì†Œ ì €ì¥
SAVE_DIR = "vdb/upstage_faiss"
vectorstore.save_local(SAVE_DIR)

print("âœ… FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")
print(f"âœ… FAISS ë²¡í„° ê°œìˆ˜: {index.ntotal}")
print(f"âœ… ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {len(vectorstore.docstore)}")
